{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\GitHub\\\\Udacity_CarND_P5_Vehicle_Detection'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Full_w-o_hist_feat', 'rb') as handle:\n",
    "    trained_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = trained_data['model']\n",
    "color_space = trained_data['color_space']\n",
    "X_scaler = trained_data['scaler']\n",
    "orient = trained_data['orient']\n",
    "pix_per_cell = trained_data['pix_per_cell']\n",
    "cell_per_block = trained_data['cell_per_block']\n",
    "spatial_size = trained_data['spatial_size']\n",
    "hist_bins = trained_data['hist_bins']\n",
    "hog_channel = trained_data['hog_channel']\n",
    "hist_bins = trained_data['hist_bins']\n",
    "hog_channel = trained_data['hog_channel']\n",
    "spatial_feat = trained_data['spatial_feat']\n",
    "hist_feat = trained_data['hist_feat']\n",
    "hog_feat = trained_data['hog_feat']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('../image_data_Udacity_CarND_P5/vehicles/GTI_Far/image0000.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block,\n",
    "                     vis=False, feature_vec=True):\n",
    "    '''\n",
    "    :param img: target image to convert\n",
    "    :param orient: orient for HOG transformation\n",
    "    :param pix_per_cell: pixel for cell of HOG transformation\n",
    "    :param cell_per_block: number of cell in block\n",
    "    :param vis: Key to use visualization or not\n",
    "    :param feature_vec: Key to use feature vector\n",
    "    :return: HOG future\n",
    "    '''\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient,\n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                  transform_sqrt=True,\n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:\n",
    "        features = hog(img, orientations=orient,\n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block),\n",
    "                       transform_sqrt=True,\n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel()\n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "# Define a function to compute color histogram features\n",
    "# NEED TO CHANGE bins_range if reading .png files with mpimg!\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:, :, 0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:, :, 1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:, :, 2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "def extract_features(img_paths, color_space='RGB', spatial_size=(32, 32),\n",
    "                     hist_bins=32, orient=9,\n",
    "                     pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                     spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "\n",
    "\n",
    "    # Iterate through the list of images\n",
    "    features = []\n",
    "    for count,file in enumerate(img_paths):\n",
    "        if count % (len(img_paths)/10)==0:\n",
    "            print(\"extraction was done\",count,\"/\",len(img_paths))\n",
    "        else:\n",
    "            pass\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = cv2.imread(file)\n",
    "        image_original = np.copy(image)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if color_space != 'BGR':\n",
    "            if color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "            elif color_space == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2LUV)\n",
    "            elif color_space == 'RGB':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            elif color_space == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "            elif color_space == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "            elif color_space == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else:\n",
    "            feature_image = np.copy(image)\n",
    "\n",
    "        channel_1 = cv2.equalizeHist(feature_image[:, :, 0])\n",
    "        channel_2 = cv2.equalizeHist(feature_image[:, :, 1])\n",
    "        channel_3 = cv2.equalizeHist(feature_image[:, :, 2])\n",
    "        feature_image = cv2.merge((channel_1,channel_2,channel_3))\n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "        if hog_feat == True:\n",
    "            # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:, :, channel],\n",
    "                                                         orient, pix_per_cell, cell_per_block,\n",
    "                                                         vis=False, feature_vec=True))\n",
    "                    # f,image_tosho = get_hog_features(feature_image[:, :, channel],orient, pix_per_cell, cell_per_block,\n",
    "                    #                                  vis=True, feature_vec=True)\n",
    "                hog_features_flat = np.ravel(hog_features)\n",
    "            else:\n",
    "                hog_features_flat = get_hog_features(feature_image[:, :, hog_channel], orient,\n",
    "                                                     pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features_flat)\n",
    "            temp_result = np.concatenate(file_features)\n",
    "#             from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        features.append(temp_result)\n",
    "    # Return list of feature vectors\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction was done 0 / 5\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:10606: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-f537e31d2863>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mcell_per_block\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcell_per_block\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mhog_channel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhog_channel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspatial_feat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspatial_feat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mhist_feat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhog_feat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhog_feat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;32m<ipython-input-15-a770ae24b84d>\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(img_paths, color_space, spatial_size, hist_bins, orient, pix_per_cell, cell_per_block, hog_channel, spatial_feat, hist_feat, hog_feat)\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mfeature_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2LUV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mcolor_space\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'RGB'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m                 \u001b[0mfeature_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mcolor_space\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'HLS'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0mfeature_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2HLS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:10606: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n"
     ]
    }
   ],
   "source": [
    "X_test = ['../image_data_Udacity_CarND_P5/GTI_Right/KITTI_extracted/image0000.png',\n",
    "         '../image_data_Udacity_CarND_P5/vehicles/KITTI_extracted/2.png',\n",
    "         '../image_data_Udacity_CarND_P5/vehicles/KITTI_extracted/3.png',\n",
    "         '../image_data_Udacity_CarND_P5/vehicles/KITTI_extracted/4.png',\n",
    "         '../image_data_Udacity_CarND_P5/vehicles/KITTI_extracted/5.png']\n",
    "\n",
    "X_feature = extract_features(\n",
    "    X_test, color_space=color_space,\n",
    "    spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "    orient=orient, pix_per_cell=pix_per_cell,\n",
    "    cell_per_block=cell_per_block,\n",
    "    hog_channel=hog_channel, spatial_feat=spatial_feat,\n",
    "    hist_feat=True, hog_feat=hog_feat\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X_scaler.transform(X_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.predict(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hitoshi\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "if spatial_feat == True:\n",
    "    spatial_features = bin_spatial(img, size=spatial_size)\n",
    "\n",
    "hist_feat = True\n",
    "if hist_feat == True:\n",
    "    # Apply color_hist()\n",
    "    hist_features = color_hist(img, nbins=hist_bins)\n",
    "if hog_feat == True:\n",
    "    hog_1 = get_hog_features(img[:,:,0], orient, pix_per_cell, cell_per_block,\n",
    "                             vis=False, feature_vec=True) \n",
    "    hog_2 = get_hog_features(img[:,:,1], orient, pix_per_cell, cell_per_block,\n",
    "                         vis=False, feature_vec=True) \n",
    "    hog_3 = get_hog_features(img[:,:,2], orient, pix_per_cell, cell_per_block,\n",
    "                             vis=False, feature_vec=True) \n",
    "    hog_feature = np.ravel(cv2.merge((hog_1,hog_2,hog_3)))\n",
    "\n",
    "test_img = np.concatenate([spatial_features,hist_features,hog_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.413629857981576"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaler.transform([test_img]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svc.predict(X_scaler.transform([test_img]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = ['../image_data_Udacity_CarND_P5/non-vehicles/GTI/image6.png']\n",
    "\n",
    "X_feature = extract_features(\n",
    "    X_test, color_space=color_space,\n",
    "    spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "    orient=orient, pix_per_cell=pix_per_cell,\n",
    "    cell_per_block=cell_per_block,\n",
    "    hog_channel=hog_channel, spatial_feat=spatial_feat,\n",
    "    hist_feat=True, hog_feat=hog_feat\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_feature[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8460,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaler.var_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(X_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Scaler_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Scaler_data.transform([X_feature[0][1:5],X_feature[1][6:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-c5f626676d37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mfeature_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2LUV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcolor_space\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'RGB'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mfeature_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcolor_space\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'HLS'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mfeature_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2HLS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "if color_space != 'BGR':\n",
    "    if color_space == 'HSV':\n",
    "        feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    elif color_space == 'LUV':\n",
    "        feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "    elif color_space == 'RGB':\n",
    "        feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    elif color_space == 'HLS':\n",
    "        feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    elif color_space == 'YUV':\n",
    "        feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    elif color_space == 'YCrCb':\n",
    "        feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "else:\n",
    "    feature_image = np.copy(img)\n",
    "\n",
    "ch1 = img[:,:,0]\n",
    "ch2 = img[:,:,1]\n",
    "ch3 = img[:,:,2]\n",
    "\n",
    "# Define blocks and steps as above\n",
    "nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1\n",
    "nfeat_per_block = orient*cell_per_block**2\n",
    "\n",
    "# # Compute individual channel HOG features for the entire image\n",
    "# def get_hog_features(img, orient, pix_per_cell, cell_per_block,\n",
    "#                      vis=False, feature_vec=True):\n",
    "\n",
    "channel_1 = cv2.equalizeHist(feature_image[:, :, 0])\n",
    "channel_2 = cv2.equalizeHist(feature_image[:, :, 1])\n",
    "channel_3 = cv2.equalizeHist(feature_image[:, :, 2])\n",
    "feature_image = cv2.merge((channel_1,channel_2,channel_3))\n",
    "\n",
    "file_features = []\n",
    "if spatial_feat == True:\n",
    "    spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "    file_features.append(spatial_features)\n",
    "\n",
    "if hist_feat == True:\n",
    "    # Apply color_hist()\n",
    "    hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "    file_features.append(hist_features)\n",
    "if hog_feat == True:\n",
    "    # Call get_hog_features() with vis=False, feature_vec=True\n",
    "    if hog_channel == 'ALL':\n",
    "        hog_features = []\n",
    "        for channel in range(feature_image.shape[2]):\n",
    "            hog_features.append(get_hog_features(feature_image[:, :, channel],\n",
    "                                                 orient, pix_per_cell, cell_per_block,\n",
    "                                                 vis=False, feature_vec=True))\n",
    "            # f,image_tosho = get_hog_features(feature_image[:, :, channel],orient, pix_per_cell, cell_per_block,\n",
    "            #                                  vis=True, feature_vec=True)\n",
    "        hog_features = np.ravel(hog_features)\n",
    "else:\n",
    "    hog_features = get_hog_features(feature_image[:, :, hog_channel], orient,\n",
    "                                    pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "file_features.append(hog_features)\n",
    "temp_result = np.concatenate(file_features)\n",
    "\n",
    "\n",
    "# test_features = X_scaler.transform(np.hstack((spatial_features, hog_features)).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hog_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-bfcae4e53c68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhog_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'hog_features' is not defined"
     ]
    }
   ],
   "source": [
    "hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.ravel(hog_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_scaler.transform(np.hstack((spatial_features, hog_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (spatial_feat == True) & (hist_feat == True):\n",
    "    test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))\n",
    "elif (spatial_feat == True) & (hist_feat == False):\n",
    "    test_features = X_scaler.transform(np.hstack((spatial_features, hog_features)).reshape(1, -1))\n",
    "elif (spatial_feat == False) & (hist_feat == True):\n",
    "    test_features = X_scaler.transform(np.hstack((hist_feat, hog_features)).reshape(1, -1))\n",
    "else:\n",
    "    test_features = X_scaler.transform(np.hstack((hog_features)).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hog1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.path.exists('../image_data_Udacity_CarND_P5/vehicles/GTI_Far')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_car_far = glob.glob('../image_data_Udacity_CarND_P5/vehicles/GTI_Far/*.png')\n",
    "images_car_left = glob.glob('../image_data_Udacity_CarND_P5/vehicles/GTI_Left/*.png')\n",
    "images_car_MiddleClose = glob.glob('../image_data_Udacity_CarND_P5/vehicles/GTI_MiddleClose/*.png')\n",
    "images_car_right = glob.glob('../image_data_Udacity_CarND_P5/vehicles/GTI_Right/*.png')\n",
    "images_car_KITTI_extracted = glob.glob('../image_data_Udacity_CarND_P5/vehicles/KITTI_extracted/*.png')\n",
    "images_noncar_Extras = glob.glob('../image_data_Udacity_CarND_P5/non-vehicles/Extras/*.png')\n",
    "images_noncar_GIT = glob.glob('../image_data_Udacity_CarND_P5/non-vehicles/GTI/*.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_noncar_GIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "IMAGE_DATA_PATH = os.path.join('..','image_data_Udacity_CarND_P5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "od_data = pd.read_csv(os.path.join(IMAGE_DATA_PATH,'od_data.csv'))\n",
    "odc_data = pd.read_csv(os.path.join(IMAGE_DATA_PATH,'odc_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odc_data[odc_data.label == 'Car'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "car_label = pd.concat([od_data[od_data.label == 'car'].path,\n",
    "                       odc_data[odc_data.label == 'Car'].path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_car_label = pd.concat([od_data[(od_data.label == 'trafficLight') &\n",
    "                               (od_data.label == 'pedestrian') &\n",
    "                               (od_data.label == 'biker') ].path,\n",
    "                       odc_data[odc_data.label == 'Pedestrian'].path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odc_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "od_data.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odc_data[odc_data.label=='Car'].path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "im = cv2.imread(odc_data[odc_data.label=='Car'].path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Udacity data (object-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Data exploration visualization code goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "\n",
    "number_of_sample = 10\n",
    "paths = random.sample(list(od_data[od_data.label=='car'].path), number_of_sample)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 20))\n",
    "for i in range(number_of_sample):\n",
    "    exec('ax' + str(i+1) +'= fig.add_subplot(9,5,' + str(i+1) +')') \n",
    "    img = cv2.imread(paths[i])\n",
    "    exec('ax' + str(i+1) +'.imshow(img)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_sample = 10\n",
    "paths = random.sample(list(od_data[od_data.label=='truck'].path), number_of_sample)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 20))\n",
    "for i in range(number_of_sample):\n",
    "    exec('ax' + str(i+1) +'= fig.add_subplot(9,5,' + str(i+1) +')') \n",
    "    img = cv2.imread(paths[i])\n",
    "    exec('ax' + str(i+1) +'.imshow(img)')\n",
    "#     exec('ax' + str(i+1) +'.set_title(' + str(i) + ')')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_sample = 10\n",
    "paths = random.sample(list(od_data[od_data.label=='trafficLight'].path), number_of_sample)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 20))\n",
    "for i in range(number_of_sample):\n",
    "    exec('ax' + str(i+1) +'= fig.add_subplot(9,5,' + str(i+1) +')') \n",
    "    img = cv2.imread(paths[i])\n",
    "    exec('ax' + str(i+1) +'.imshow(img)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_sample = 10\n",
    "paths = random.sample(list(od_data[od_data.label=='pedestrian'].path), number_of_sample)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 20))\n",
    "for i in range(number_of_sample):\n",
    "    exec('ax' + str(i+1) +'= fig.add_subplot(9,5,' + str(i+1) +')') \n",
    "    img = cv2.imread(paths[i])\n",
    "    exec('ax' + str(i+1) +'.imshow(img)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_sample = 10\n",
    "paths = random.sample(list(od_data[od_data.label=='biker'].path), number_of_sample)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 20))\n",
    "for i in range(number_of_sample):\n",
    "    exec('ax' + str(i+1) +'= fig.add_subplot(9,5,' + str(i+1) +')') \n",
    "    img = cv2.imread(paths[i])\n",
    "    exec('ax' + str(i+1) +'.imshow(img)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "od_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Udacity data (object-dataset-crowdai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_sample = 10\n",
    "paths = random.sample(list(odc_data[odc_data.label=='Car'].path), number_of_sample)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 20))\n",
    "for i in range(number_of_sample):\n",
    "    exec('ax' + str(i+1) +'= fig.add_subplot(9,5,' + str(i+1) +')') \n",
    "    img = cv2.imread(paths[i])\n",
    "    exec('ax' + str(i+1) +'.imshow(img)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_sample = 10\n",
    "paths = random.sample(list(odc_data[odc_data.label=='Truck'].path), number_of_sample)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 20))\n",
    "for i in range(number_of_sample):\n",
    "    exec('ax' + str(i+1) +'= fig.add_subplot(9,5,' + str(i+1) +')') \n",
    "    img = cv2.imread(paths[i])\n",
    "    exec('ax' + str(i+1) +'.imshow(img)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_sample = 10\n",
    "paths = random.sample(list(odc_data[odc_data.label=='Pedestrian'].path), number_of_sample)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 20))\n",
    "for i in range(number_of_sample):\n",
    "    exec('ax' + str(i+1) +'= fig.add_subplot(9,5,' + str(i+1) +')') \n",
    "    img = cv2.imread(paths[i])\n",
    "    exec('ax' + str(i+1) +'.imshow(img)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "odc_data.label.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
